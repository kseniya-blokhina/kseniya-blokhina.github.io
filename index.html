<h1 id="utf-8-utf-16">UTF-8 &amp; UTF-16</h1>
<p>While working with different types of information such as text strings, images or videos computers deal with information presented in a digital form, and therefore the storage of information including text lines and individual graphic symbols proceeds in a digital form. The tool that allows you to describe the rules for storing text and the correspondence of the digital code of a symbol to its graphic image is the encoding.</p>
<p>In the early days of the personal computer, 7-bit code pages were used to store values in memory with a single graphic symbol corresponding to each one. Such code pages could contain up to 128 different characters, and this was enough for all letters of the English alphabet, as well as basic mathematical symbols and punctuation marks. The main encoding and the corresponding code page were named ASCII (American Standard Code for Information Interchange). Then, the spread of computer technology around the world resulted in a grown up demand for encoding of various national languages characters. The original ASCII code was used as the base one and occupied the first 7 bits, and the 8th was added for the national language, so all the necessary national characters were encoded with the most significant bit and occupied the remaining 128 positions while maintaining the support of the English language. Due to the growing number of different encodings and corresponding code pages, manufacturers of operating systems and software began to have difficulties with technical support and updating their product to ensure compatibility.</p>
<p>The chaos associated with the lack of common standards forced the creation of a universal encoding that can contain all the specific characters at once and take into account the features of the writing of different nations of the world. This aim was achieved by creating a single standard that met these requirements, containing also an algorithm for determining encodings. In 1991 Unicode Inc. in collaboration with ISO, began developing the Unicode and ISO / IEC 10646 standards, respectively. Subsequently, the updating of these standards also took place approximately simultaneously. One of the main principles of Unicode is the idea that each character is understood as some kind of abstraction, i.e. regardless of how the characters are stored in computer memory or displayed on an input and output device, the character will remain the same. This idea is well known in programming as encapsulation or separation of interface from implementation.</p>
<p>According to the new standard, it was decided to dedicate 2<sup>16</sup> (65 535) code positions for a set of national symbols, which was named Basic Multilingual Plane (BMP). At first, the UCS (Universal Character Set) encoding was developed according to the ISO 10646 standard in the UCS-2 and UCS-4 standards with a fixed code length of 16 and 32 bits, respectively. The fixed multiple of two code length and a simple coding method on the one hand ensured high speed of text processing, but on the other hand such code occupied too much space. </p>
<p>Then began the development of the UTF (Unicode Transformation Format) variable-length encodings, where the number of bytes occupied by a character depends on its location in the code table. The UTF-16 encoding was created based on UCS-2, wherein the code points were outside the BMP and each character was written in 2 or 4 bytes (surrogate pair) in the range from 0 to FFFF<sub>16</sub> with an increased number of code points to 2<sup>20</sup>+2<sup>16</sup>âˆ’2048 (1 112 064). Seeing as most communication and storage protocols are defined for bytes with each unit taking two 8-bit bytes. The order of the bytes may depend on the endianness of the computer architecture. Decreasing and increasing numeric significances of bytes are known as big-endian and little-endian, respectively. Later it was provided the UTF-8 encoding, wherein each character could be written in 1, 2, 3 or 4 bytes, and the number of code points was increased to 2<sup>20</sup> (2 097 152). However, for compatibility with UTF-16 the same number of code points has remained. Unlike UTF-16, UTF-8  UTF-8 is independent of byte order. </p>
<p>Today there are 17 planes that can accommodate 1,114,112 code points. They are identified by the numbers 0 to 16 with possible values from 00 to 10<sub>16</sub> of the first two positions in six position hexadecimal format (U+hhhhhh). The Basic Multilingual Plane (BMP) is defined under the 0 plane. The other planes are called &quot;supplementary planes&quot; with planes 4-13 (40000-DFFFF) remaining unused. Hence it appears to be no lack of code points now and both UTF-8 and UTF-16 meet present requirements.</p>

